import asyncio
import os
import signal
import logging
import json
import shutil
import ffmpeg
from fastapi import FastAPI, BackgroundTasks, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import List, Optional, Dict
from pathlib import Path

# Import Core Services
from core.scanner import VideoScanner
from core.subtitle_processor import SubtitleProcessor
from core.transcriber import VideoTranscriber
from core.translator import SubtitleTranslator
from core.muxer import VideoMuxer
from core.events import event_manager, setup_logging_bridge  # <--- Added bridge

# --- LOGGING ---
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger("SubStudio")

# --- DATA MODELS ---
class VideoJob(BaseModel):
    name: str
    path: str
    srtFoundPath: Optional[str] = "None"
    src: str = "auto"
    out: List[str] = ["fr"]
    workflowMode: str = "srt" 
    syncOffset: int = 0

class GlobalOptions(BaseModel):
    transcriptionEngine: str = "base"
    generateSRT: bool = True
    muxIntoMkv: bool = True
    cleanUp: bool = False

class ProcessRequest(BaseModel):
    videos: List[VideoJob]
    globalOptions: GlobalOptions

# --- TASK MANAGER ---
class TaskManager:
    def __init__(self):
        self.active_pid: Optional[int] = None
        self.is_aborted: bool = False
        self.queue: List[VideoJob] = []
        self.current_fid: Optional[str] = None
        self.artifacts: List[str] = []

    def register_artifact(self, path: str):
        if path and path not in self.artifacts:
            self.artifacts.append(path)
            logger.info(f"üìç Registered artifact: {path}")

    def abort_all(self):
        logger.warning("üö® [ABORT] Stop signal received.")
        self.is_aborted = True
        self.queue = []
        if self.active_pid:
            try:
                os.kill(self.active_pid, signal.SIGTERM)
                logger.info(f"üíÄ Killed PID: {self.active_pid}")
            except Exception as e:
                logger.error(f"Failed to kill PID {self.active_pid}: {e}")
        self.cleanup_artifacts()

    def cleanup_artifacts(self):
        for path in self.artifacts:
            if os.path.exists(path):
                try:
                    os.remove(path)
                    logger.info(f"üßπ Cleaned up artifact: {path}")
                except: pass
        self.artifacts = []

# --- INITIALIZATION ---
app = FastAPI(title="SubStudio API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)

task_manager = TaskManager()
scanner = VideoScanner(base_path="/data")
processor = SubtitleProcessor()
transcriber = VideoTranscriber(model_size="base")
translator = SubtitleTranslator()
muxer = VideoMuxer()

# --- HELPER FUNCTIONS ---
def get_embedded_languages(video_path: str) -> List[str]:
    try:
        probe = ffmpeg.probe(video_path)
        return [s.get('tags', {}).get('language', 'und') for s in probe.get('streams', []) if s['codec_type'] == 'subtitle']
    except:
        return []

# --- PIPELINE EXECUTION ---
async def run_linear_pipeline(request: ProcessRequest):
    task_manager.is_aborted = False
    task_manager.queue = request.videos
    opts = request.globalOptions

    iso_map = {'fr': 'fra', 'en': 'eng', 'es': 'spa', 'de': 'deu', 'it': 'ita', 'pt': 'por', 'ja': 'jpn'}

    while task_manager.queue:
        if task_manager.is_aborted: break

        video = task_manager.queue.pop(0)
        fid = video.path 
        task_manager.current_fid = fid

        # 1. SETUP LOG BRIDGE FOR THIS FILE
        # Every logger.info inside the core modules will now be sent to this file's SSE
        log_handler = setup_logging_bridge(fid)

        try:
            logger.info(f"üé¨ [STARTING] {video.name}")
            
            embedded_langs = get_embedded_languages(video.path)
            needed_langs = []
            translated_map = {}

            for lang in video.out:
                srt_name = f"{os.path.splitext(video.path)[0]}.{lang}.srt"
                iso_3 = iso_map.get(lang, lang)
                
                if os.path.exists(srt_name):
                    logger.info(f"‚è≠Ô∏è [SKIP] {lang.upper()} SRT already exists on disk.")
                    with open(srt_name, 'r', encoding='utf-8') as f:
                        translated_map[lang] = f.read()
                elif iso_3 in embedded_langs:
                    logger.info(f"‚è≠Ô∏è [SKIP] {lang.upper()} already embedded in file.")
                else:
                    needed_langs.append(lang)

            if not needed_langs:
                logger.info(f"‚úÖ All requested languages present for {video.name}. Skipping to Muxer.")
            else:
                event_manager.emit(fid, "processing", 5, "Initializing Story Bible...")
                context_bible = translator.get_context_profile(video.name)

                srt_content = ""
                is_whisper = False

                if video.workflowMode == "srt":
                    if video.srtFoundPath == "Embedded":
                        logger.info(f"üì¶ [SOURCE] Extracting embedded SRT...")
                        # Assume muxer has an extract function now
                        srt_content = muxer.extract_subtitle(video.path) 
                    elif video.srtFoundPath and os.path.exists(video.srtFoundPath):
                        logger.info(f"üìÇ [SOURCE] Using local SRT: {video.srtFoundPath}")
                        with open(video.srtFoundPath, 'r', encoding='utf-8') as f:
                            srt_content = f.read()

                if not srt_content or video.workflowMode == "whisper":
                    logger.info(f"üéôÔ∏è [SOURCE] Running AI Transcription")
                    srt_content = transcriber.transcribe(video.path, fid, event_manager.emit, task_manager)
                    is_whisper = True

                for lang in needed_langs:
                    if task_manager.is_aborted: break
                    event_manager.emit(fid, "translating", 40, f"Translating to {lang.upper()}...")
                    translation = translator.refine_and_translate(
                        srt_content, lang, fid, event_manager.emit, task_manager, context_bible, is_whisper
                    )
                    translated_map[lang] = translation
                    
                    if opts.generateSRT:
                        srt_export_path = f"{os.path.splitext(video.path)[0]}.{lang}.srt"
                        with open(srt_export_path, "w", encoding="utf-8") as f:
                            f.write(translation)

            if opts.muxIntoMkv and not task_manager.is_aborted:
                event_manager.emit(fid, "muxing", 85, "Muxing into final MKV...")
                muxer.mux(
                    video_path=video.path,
                    translated_srts=translated_map,
                    file_id=fid,
                    on_progress=event_manager.emit,
                    task_manager=task_manager,
                    cleanup_original=opts.cleanUp
                )

            event_manager.emit(fid, "done", 100, "Successfully completed!")
            logger.info(f"‚úÖ [FINISHED] {video.name}")
            
        except Exception as e:
            logger.error(f"‚ùå [PIPELINE ERROR] {fid}: {str(e)}")
            event_manager.emit(fid, "error", 0, f"Error: {str(e)}")
        finally:
            # 2. REMOVE LOG BRIDGE TO PREVENT MEMORY LEAKS/DUPLICATE LOGS
            logging.getLogger("SubStudio").removeHandler(log_handler)
            task_manager.artifacts = []

    task_manager.current_fid = None

# --- API ENDPOINTS ---

@app.get("/api/scan")
async def scan_library(target_path: str = Query("/data")):
    items = scanner.scan(target_path=target_path, recursive=True)
    return {"files": items}

@app.post("/api/process")
async def start_processing(request: ProcessRequest, background_tasks: BackgroundTasks):
    try:
        payload_debug = json.dumps(request.model_dump(), indent=4)
        logger.info(f"\nüöÄ [INCOMING REQUEST]\n{payload_debug}\n")
    except: pass

    if task_manager.current_fid and not task_manager.is_aborted:
        task_manager.queue.extend(request.videos)
        for v in request.videos:
            event_manager.emit(v.path, "queued", 0, "Waiting in queue...")
        return {"status": "queued", "count": len(request.videos)}
    
    background_tasks.add_task(run_linear_pipeline, request)
    return {"status": "started", "video_count": len(request.videos)}

@app.post("/api/abort")
async def abort_jobs():
    task_manager.abort_all()
    return {"status": "aborted"}

@app.get("/api/events/{file_id:path}")
async def sse_endpoint(file_id: str):
    return StreamingResponse(
        event_manager.subscribe(file_id),
        media_type="text/event-stream"
    )