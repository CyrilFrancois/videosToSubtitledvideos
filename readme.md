# üé¨ AI Video Suite: Transcribe, Translate & Mux

A professional-grade media pipeline for automated subtitle generation, AI-powered translation (GPT-4), and smart MKV muxing. This application handles complex subtitle folder structures, audio-to-subtitle synchronization, and recursive folder processing.



## ‚ú® Key Features

* **Recursive Discovery:** Scan single files, specific folders, or entire directory trees.
* **Intelligent Subtitle Search:** * Internal streams (MKV/MP4 tracks).
    * Sidecar files (`video.srt`).
    * Nested structures (`subs/video_name/lang.srt`).
    * **Heuristic Selection:** Automatically picks the most complete (SDH) subtitle based on file weight and duration.
* **AI Pipeline:** * **Whisper:** Local speech-to-text for audio detection and transcription.
    * **GPT-4:** Context-aware translation using show/movie metadata for superior accuracy.
* **Sync Engine:** Adjusts external unsynchronized subtitles to match the audio track or existing internal transcription.
* **Clean Muxing:** Final output as `.mkv` with correctly tagged language tracks and "default" flags.

---

## üèóÔ∏è Architecture

The app is containerized using **Docker Compose** to manage dependencies like FFmpeg and CUDA drivers.

| Service | Technology | Responsibility |
| :--- | :--- | :--- |
| **Frontend** | Next.js / TypeScript | Interactive dashboard, File Explorer, Real-time Logs (SSE). |
| **Backend** | FastAPI (Python) | AI Engine, File Scanner, FFmpeg Muxer, GPT Integration. |
| **Storage** | Docker Volumes | Shared access to your local media library. |

---

## üìÇ Project Structure

```text
videosToSubtitledvideos/
‚îú‚îÄ‚îÄ docker-compose.yml         # Container orchestration
‚îú‚îÄ‚îÄ .env                       # API Keys & Configuration
‚îú‚îÄ‚îÄ readme.md                  # The Readme of the application you're reading right now
‚îú‚îÄ‚îÄ data/                      # YOUR MEDIA (Mounted local folder)
frontend/
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ tsconfig.json
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ globals.css         
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx         # Root layout (Fonts, Providers)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx           # The "One-Pager" Main Dashboard
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Sidebar.tsx    # The Sticky Left Column
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ GlobalProgress.tsx # The Top Neon Progress Bar
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ VideoCard.tsx      # Individual Video Row/Card
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ VideoList.tsx      # Scrollable container for cards
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts             # Backend Fetch/Axios calls
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sse.ts             # Server-Sent Events for live logs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types.ts           # TypeScript interfaces for Video/Status
‚îÇ   ‚îî‚îÄ‚îÄ hooks/
‚îÇ       ‚îî‚îÄ‚îÄ useSocket.ts       # Custom hook for real-time updates
‚îú‚îÄ‚îÄ tailwind.config.ts         # Theme configuration
‚îî‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ backend/                   # FastAPI Application
    ‚îú‚îÄ‚îÄ core/
    ‚îÇ   ‚îú‚îÄ‚îÄ scanner.py         # Subtitle & Stream discovery logic
    ‚îÇ   ‚îú‚îÄ‚îÄ transcriber.py     # OpenAI Whisper implementation
    ‚îÇ   ‚îú‚îÄ‚îÄ translator.py      # LLM Translation logic
    ‚îÇ   ‚îî‚îÄ‚îÄ muxer.py           # FFmpeg & Synchronization
    ‚îî‚îÄ‚îÄ main.py                # REST API Endpoints
    ‚îî‚îÄ‚îÄ requirements.txt       # All the needed libs
```

---

## üöÄ Getting Started

### 1. Prerequisites
* **Docker & Docker Compose** installed.
* **NVIDIA Container Toolkit** (Optional, for GPU acceleration).
* **OpenAI API Key** (For context-aware translation).

### 2. Configuration
Create a `.env` file in the root directory:
```env
OPENAI_API_KEY=your_key_here
MEDIA_PATH=./data
WHISPER_MODEL=base  # tiny, base, small, medium, large
```

### 3. Deployment
```bash
docker-compose up --build
docker-compose up
```
The application will be available at:
* **Frontend:** `http://localhost:3000`
* **Backend API:** `http://localhost:8000/docs`

---

## ‚öôÔ∏è Logic Workflow

1.  **Detection:** User selects a root folder. The `Scanner` identifies every video and probes for existing audio/subtitle tracks.
2.  **Selection:** User picks target languages (e.g., English -> French/Japanese).
3.  **Synchronization (If needed):** If external subtitles are chosen, the engine compares their timestamps with the audio waveform to fix offsets.
4.  **Translation:** Subtitles are chunked and sent to GPT-4 with "System Prompts" derived from movie metadata to maintain tone.
5.  **Finalization:** FFmpeg muxes all chosen streams into a new `.mkv` file, preserving quality while organizing tracks.

---

## üó∫Ô∏è Roadmap
- [ ] Auto-sync via Cross-Correlation of audio waveforms.
- [ ] TMDB API integration for automatic show metadata.
- [ ] User-defined "Translation Glossary" for specific terminology.